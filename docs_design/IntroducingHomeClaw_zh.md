# 欢迎来到 HomeClaw 说明

本文档用于**介绍 HomeClaw**：它的由来、理念与功能。在深入 README、Design.md 或使用指南之前，可先在此了解全貌。

---

## 1. 由来

HomeClaw 源自半年多前我们设计与实现的 **GPT4People** 项目。经过多次改动与改进后，我们将其更名为 **HomeClaw**。核心想法不变：一个在家运行的 AI 助手，通过你已有的渠道与你对话，并把数据与隐私留在你这边。

---

## 2. 我们的定位（以及我们不是什么）

部分设计思路与 **OpenClaw** 相似：**渠道**（如何触达助手）、**从任意地方访问家中电脑**、**让 LLM 替你做事**。但我们并非以“控制”电脑为目标，而是希望**家中电脑为我们做事**，同时**保护隐私**。因此：你的机器、你的数据、你的助手。

---

## 3. 先本地 LLM，再云端

起初我们聚焦于在自有硬件上运行的**本地 LLM**（如 llama.cpp、GGUF）。之后通过 **LiteLLM** 增加了**云端模型**支持（OpenAI、Google Gemini、DeepSeek、Anthropic 等）。因此你可以全用本地、全用云端，或**混合使用**——例如聊天用本地、嵌入用云端，或反之。均可配置。

---

## 4. 记忆：每用户一个沙箱

我们加入了**记忆系统**，作为**每用户一个沙箱**。若多位家庭成员共用同一 HomeClaw 实例，每个人的数据是隔离的：你的对话与记忆不会泄露给其他用户。这在软件层面得到保证。当然，若有人能物理接触你的电脑并查看文件，我们无法控制——但在系统内部，用户是隔离且安全的。

记忆是**基于 RAG**（检索增强）的：助手可以跨会话回忆“我们曾就 X 说过什么”，依托向量库与对话历史。因此不仅是“当前会话”，而是**每用户长期、语义化的记忆**。

---

## 5. 一句话概括

HomeClaw 是一个**支持本地与云端 LLM、多用户、基于记忆、自托管**的系统。你在自己的机器（或多台机器）上运行；通过邮件、Telegram、Discord、WebChat、CLI 或任何能向它 POST 的机器人与之对话；它会记忆、推理并使用工具与插件——一切以你的隐私为前提。

---

## 6. 借鉴 OpenClaw，扩展 HomeClaw

我们借鉴 **OpenClaw**，并让 **Skills** 可直接复用。HomeClaw 的技能放在 `config/skills/` 下，以 **SKILL.md**（名称、描述、工作流）定义。若一个技能可以描述为“按这种方式使用这些工具”，通常无需改代码即可放入使用。

我们支持两种**扩展**方式：

- **内置插件**（Python）：位于 `plugins/` 目录；一个插件对应一个专注功能（如天气、新闻、邮件）。LLM 通过 `route_to_plugin` 路由到它们。
- **外部插件**（任意语言）：以独立 HTTP 服务运行（Node.js、Go、Java 等）；向 Core 注册并实现简单的请求/响应约定。参见 docs_design/PluginsGuide.md 与 docs_design/PluginStandard.md。

因此你得到**一个智能体**，但可以通过技能与插件简单扩展——若需要更多容量或隔离，也可以在同一台或不同电脑上**运行更多 HomeClaw 实例**。

---

## 7. 插件：扩展 HomeClaw 的能力

**插件**用于为 HomeClaw 增加专注能力——天气、新闻、邮件、自定义 API 或任何你希望助手完成的事。它们在不改动核心的前提下扩展能力，非常重要。

- **插件是什么：** 一个插件 = **一个专注功能**。当用户的问题明显匹配某个插件（如“巴黎天气怎么样？”）时，LLM 会路由到该插件；插件运行、拉取数据或调用 API，并返回结果。因此助手不仅能聊天，还能查天气、发邮件、取新闻或调用你自己的服务。

- **内置插件（Python）：** 位于 `plugins/` 目录。每个插件有 **plugin.yaml**（id、描述）、**config.yml**（API 密钥、默认值）和 **plugin.py**（继承 `BasePlugin` 并实现 `run()` 的类）。Core 在启动时发现它们，无需额外注册。示例：**Weather**、**News**、**Mail**。你可以按相同结构在 `plugins/` 下新增目录以添加自己的插件。

- **外部插件（任意语言）：** 以**独立 HTTP 服务**运行（Node.js、Go、Java、Rust 等）。你实现简单约定：接收请求（用户输入、上下文）并返回结果。通过 `POST /api/plugins/register` 向 Core **注册**；之后 Core 会像内置插件一样路由到你的服务。因此你可以用任意语言扩展 HomeClaw，或接入已有服务。

插件与**工具**（exec、browser、cron、file、memory、网页搜索等）和**技能**（SKILL.md 描述的工作流）一起工作。它们共同构成一个能聊天、记忆并做事的智能体，而你通过添加插件扩展这份能力。细节见 **docs_design/PluginsGuide.md**、**docs_design/HowToWriteAPlugin.md** 与 **docs_design/PluginStandard.md**。

---

## 8. 一个智能体，多种 LLM

我们是**一个智能体**（一个身份、一份记忆、一套工具与技能），但支持**多种可配置的 LLM**。你可以设置主模型与嵌入模型（均可为本地或云端），未来我们还会支持按任务使用不同模型（如简单任务用本地、复杂任务用云端）。因此：一个助手，多种模型——均可配置。

---

## 9. 记忆：简单版与企业版

**记忆**我们提供简单默认与企业级两种选择：

- **简单：** **SQLite**（对话历史、会话）+ **Chroma**（RAG 向量库）+ **Kuzu**（可选图库）。无需额外服务，适合家庭与小规模部署。
- **企业：** 可切换为 **PostgreSQL**（关系型）、**Qdrant** 或 **LanceDB**（向量）、**Neo4j**（图）。我们也支持以 **Cognee** 作为默认记忆引擎，统一关系型、向量与图，并可复用相同后端。参见 docs_design/MemoryAndDatabase.md。

因此可以从简单起步，需要时再扩展。

---

## 10. 目前你能做什么

- **对话：** 通过 **WebChat**、**CLI**、**Telegram**、**Discord**、**Slack**、**邮件**、**Matrix**、**Tinode**、**微信**、**WhatsApp** 或任何能向 **/inbound**（或我们的 Webhook 中继）POST 的机器人与 HomeClaw 对话。
- **记忆：** RAG + 对话历史 + 可选的每用户档案与知识库。
- **做事：** **工具**（exec、browser、cron、file、memory、网页搜索、会话等）与**插件**（天气、新闻、邮件、自定义 API）。LLM 按名称带参数调用工具，在意图匹配时路由到插件。
- **使用技能：** 放入基于 SKILL.md 的工作流（包括来自 OpenClaw 的），让助手知道如何组合工具完成任务。
- **多用户：** 在 `config/user.yml` 中添加用户；每个用户拥有隔离的对话、记忆与档案。

---

## 11. 下一步（我们的方向）

1. **更易用**  
   我们希望通过**工具与界面**让 HomeClaw 更易用——例如更好的入门流程、配置向导和稳定的 WebChat，使你不必通读手册即可上手。

2. **混合本地与云端模型**  
   我们想探索**如何混合本地与云端模型**，让**多数事情由本地模型完成**，**仅在需要时使用云端模型**（如更难的问题、更长上下文或用户明确要求）。这样在控制成本与隐私的同时，仍可在需要时借助云端。

---

## 12. 接下来可以看什么

- **README.md** — 概览、快速开始、渠道、插件、技能。  
- **Design.md** — 架构、Core、渠道、记忆、工具、插件。  
- **Channel.md** — 渠道的使用与配置。  
- **HOW_TO_USE.md** — 分步安装与使用。  
- **docs_design/** — PluginsGuide、SkillsGuide、MemoryAndDatabase、ToolsSkillsPlugins 等。

感谢你对 HomeClaw 的关注。希望它能帮你把 AI 带回家——按你的方式。
